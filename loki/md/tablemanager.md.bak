
tableManager object DEPRECATED Configuration for the table-manager. The table-manager is only necessary when using a deprecated index type such as Cassandra, Bigtable, or DynamoDB, it has not been necessary since loki introduced self- contained index types like 'boltdb-shipper' and 'tsdb'. This will be removed in a future helm chart.

{
  "affinity": {
    "podAntiAffinity": {
      "requiredDuringSchedulingIgnoredDuringExecution": [
        {
          "labelSelector": {
            "matchLabels": {
              "app.kubernetes.io/component": "table-manager",
              "app.kubernetes.io/instance": "{{ .Release.Name }}",
              "app.kubernetes.io/name": "{{ include \"loki.name\" . }}"
            }
          },
          "topologyKey": "kubernetes.io/hostname"
        }
      ]
    }
  },
  "annotations": {},
  "command": null,
  "dnsConfig": {},
  "enabled": false,
  "extraArgs": [],
  "extraContainers": [],
  "extraEnv": [],
  "extraEnvFrom": [],
  "extraVolumeMounts": [],
  "extraVolumes": [],
  "hostUsers": "nil",
  "image": {
    "registry": null,
    "repository": null,
    "tag": null
  },
  "nodeSelector": {},
  "podAnnotations": {},
  "podLabels": {},
  "priorityClassName": null,
  "resources": {},
  "retention_deletes_enabled": false,
  "retention_period": 0,
  "service": {
    "annotations": {},
    "labels": {}
  },
  "terminationGracePeriodSeconds": 30,
  "tolerations": []
}

tableManager.affinity object Affinity for table-manager pods. The value will be passed through tpl.

Hard node and anti-affinity

tableManager.annotations object Annotations for table-manager deployment

{}

tableManager.command string Command to execute instead of defined in Docker image

null

tableManager.dnsConfig object DNS config table-manager pods

{}

tableManager.enabled bool Specifies whether the table-manager should be enabled

false

tableManager.extraArgs list Additional CLI args for the table-manager

[]

tableManager.extraContainers list Containers to add to the table-manager pods

[]

tableManager.extraEnv list Environment variables to add to the table-manager pods

[]

tableManager.extraEnvFrom list Environment variables from secrets or configmaps to add to the table-manager pods

[]

tableManager.extraVolumeMounts list Volume mounts to add to the table-manager pods

[]

tableManager.extraVolumes list Volumes to add to the table-manager pods

[]

tableManager.hostUsers string Use the host's user namespace in table-manager pods

"nil"

tableManager.image.registry string The Docker registry for the table-manager image. Overrides `loki.image.registry`

null

tableManager.image.repository string Docker image repository for the table-manager image. Overrides `loki.image.repository`

null

tableManager.image.tag string Docker image tag for the table-manager image. Overrides `loki.image.tag`

null

tableManager.nodeSelector object Node selector for table-manager pods

{}

tableManager.podAnnotations object Annotations for table-manager pods

{}

tableManager.podLabels object Labels for table-manager pods

{}

tableManager.priorityClassName string The name of the PriorityClass for table-manager pods

null

tableManager.resources object Resource requests and limits for the table-manager

{}

tableManager.retention_deletes_enabled bool Enable deletes by retention

false

tableManager.retention_period int Set retention period

0

tableManager.service.annotations object Annotations for table-manager Service

{}

tableManager.service.labels object Additional labels for table-manager Service

{}

tableManager.terminationGracePeriodSeconds int Grace period to allow the table-manager to shutdown before it is killed

30

tableManager.tolerations list Tolerations for table-manager pods

[]

test object Section for configuring optional Helm test

{
  "annotations": {},
  "canaryServiceAddress": "<http://loki-canary:3500/metrics>",
  "enabled": true,
  "hostUsers": "nil",
  "image": {
    "digest": null,
    "pullPolicy": "IfNotPresent",
    "registry": "docker.io",
    "repository": "grafana/loki-helm-test",
    "tag": "latest"
  },
  "labels": {},
  "prometheusAddress": "",
  "timeout": "1m"
}

test.annotations object Additional annotations for test pods

{}

test.canaryServiceAddress string Used to directly query the metrics endpoint of the canary for testing, this approach avoids needing prometheus for testing. This in a newer approach to using prometheusAddress such that tests do not have a dependency on prometheus

"<http://loki-canary:3500/metrics>"

test.hostUsers string Use the host's user namespace in test pods

"nil"

test.image object Image to use for loki canary

{
  "digest": null,
  "pullPolicy": "IfNotPresent",
  "registry": "docker.io",
  "repository": "grafana/loki-helm-test",
  "tag": "latest"
}

test.image.digest string Overrides the image tag with an image digest

null

test.image.pullPolicy string Docker image pull policy

"IfNotPresent"

test.image.registry string The Docker registry

"docker.io"

test.image.repository string Docker image repository

"grafana/loki-helm-test"

test.image.tag string Overrides the image tag whose default is the chart's appVersion

"latest"

test.labels object Additional labels for the test pods

{}

test.prometheusAddress string Address of the prometheus server to query for the test. This overrides any value set for canaryServiceAddress. This is kept for backward compatibility and may be removed in future releases. Previous value was '<http://prometheus:9090>'

""

test.timeout string Number of times to retry the test before failing

"1m"

write.affinity object Affinity for write pods. The value will be passed through tpl.

Hard node anti-affinity

write.annotations object Annotations for write StatefulSet

{}

write.autoscaling.behavior object Behavior policies while scaling.

{
  "scaleDown": {
    "policies": [
      {
        "periodSeconds": 1800,
        "type": "Pods",
        "value": 1
      }
    ],
    "stabilizationWindowSeconds": 3600
  },
  "scaleUp": {
    "policies": [
      {
        "periodSeconds": 900,
        "type": "Pods",
        "value": 1
      }
    ]
  }
}

write.autoscaling.behavior.scaleUp object see <https://github.com/grafana/loki/blob/main/docs/sources/operations/storage/wal.md#how-to-scale-updown> for scaledown details

{
  "policies": [
    {
      "periodSeconds": 900,
      "type": "Pods",
      "value": 1
    }
  ]
}

write.autoscaling.enabled bool Enable autoscaling for the write.

false

write.autoscaling.maxReplicas int Maximum autoscaling replicas for the write.

6

write.autoscaling.minReplicas int Minimum autoscaling replicas for the write.

2

write.autoscaling.targetCPUUtilizationPercentage int Target CPU utilisation percentage for the write.

60

write.autoscaling.targetMemoryUtilizationPercentage string Target memory utilization percentage for the write.

null

write.dnsConfig object DNS config for write pods

{}

write.extraArgs list Additional CLI args for the write

[]

write.extraContainers list Containers to add to the write pods

[]

write.extraEnv list Environment variables to add to the write pods

[]

write.extraEnvFrom list Environment variables from secrets or configmaps to add to the write pods

[]

write.extraVolumeClaimTemplates list volumeClaimTemplates to add to StatefulSet

[]

write.extraVolumeMounts list Volume mounts to add to the write pods

[]

write.extraVolumes list Volumes to add to the write pods

[]

write.hostUsers string Use the host's user namespace in the write pods.

"nil"

write.image.registry string The Docker registry for the write image. Overrides `loki.image.registry`

null

write.image.repository string Docker image repository for the write image. Overrides `loki.image.repository`

null

write.image.tag string Docker image tag for the write image. Overrides `loki.image.tag`

null

write.initContainers list Init containers to add to the write pods

[]

write.lifecycle object Lifecycle for the write container

{}

write.nodeSelector object Node selector for write pods

{}

write.persistence.accessModes list Set access modes on the PersistentVolumeClaim

[
  "ReadWriteOnce"
]

write.persistence.annotations object Annotations for volume claim

{}

write.persistence.dataVolumeParameters object Parameters used for the `data` volume when volumeClaimEnabled if false

{
  "emptyDir": {}
}

write.persistence.enableStatefulSetAutoDeletePVC bool Enable StatefulSetAutoDeletePVC feature

false

write.persistence.labels object Labels for volume claim

{}

write.persistence.selector string Selector for persistent disk

null

write.persistence.size string Size of persistent disk

"10Gi"

write.persistence.storageClass string Storage class to be used. If defined, storageClassName: . If set to "-", storageClassName: "", which disables dynamic provisioning. If empty or set to null, no storageClassName spec is set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).

null

write.persistence.volumeClaimsEnabled bool Enable volume claims in pod spec

true

write.podAnnotations object Annotations for write pods

{}

write.podLabels object Additional labels for each `write` pod

{}

write.podManagementPolicy string The default is to deploy all pods in parallel.

"Parallel"

write.priorityClassName string The name of the PriorityClass for write pods

null

write.replicas int Number of replicas for the write

3

write.resources object Resource requests and limits for the write

{}

write.selectorLabels object Additional selector labels for each `write` pod

{}

write.service.annotations object Annotations for write Service

{}

write.service.labels object Additional labels for write Service

{}

write.service.type string Service Type for write Service

"ClusterIP"

write.targetModule string Comma-separated list of Loki modules to load for the write

"write"

write.terminationGracePeriodSeconds int Grace period to allow the write to shutdown before it is killed. Especially for the ingester, this must be increased. It must be long enough so writes can be gracefully shutdown flushing/transferring all data and to successfully leave the member ring on shutdown.

300

write.tolerations list Tolerations for write pods

[]

write.topologySpreadConstraints list Topology Spread Constraints for write pods The value will be passed through tpl.

[]
